{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "em4EjOwFffq2"
      },
      "outputs": [],
      "source": [
        "# executar esse script somente no google colab\n",
        "%%shell\n",
        "sudo apt -y update\n",
        "sudo apt install -y wget curl unzip\n",
        "wget http://archive.ubuntu.com/ubuntu/pool/main/libu/libu2f-host/libu2f-udev_1.1.4-1_all.deb\n",
        "dpkg -i libu2f-udev_1.1.4-1_all.deb\n",
        "wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n",
        "dpkg -i google-chrome-stable_current_amd64.deb\n",
        "CHROME_DRIVER_VERSION=`curl -sS chromedriver.storage.googleapis.com/LATEST_RELEASE`\n",
        "wget -N https://chromedriver.storage.googleapis.com/$CHROME_DRIVER_VERSION/chromedriver_linux64.zip -P /tmp/\n",
        "unzip -o /tmp/chromedriver_linux64.zip -d /tmp/\n",
        "chmod +x /tmp/chromedriver\n",
        "mv /tmp/chromedriver /usr/local/bin/chromedriver\n",
        "pip install selenium"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install chromedriver-autoinstaller"
      ],
      "metadata": {
        "id": "Am4y5DgQfsZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from selenium.webdriver.common.by import By\n",
        "from time import sleep\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import openpyxl\n",
        "import requests\n",
        "from io import BytesIO\n",
        "import chromedriver_autoinstaller\n",
        "\n",
        "import sys\n",
        "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\n",
        "\n",
        "# ------------------ Dependencias --------------------------\n",
        "\n",
        "# Configurando o WebDriver\n",
        "\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.add_argument('--headless') # ensure GUI is off\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "\n",
        "# definindo o caminho para chromedriver de acordo com sua configuração\n",
        "chromedriver_autoinstaller.install()\n",
        "\n",
        "# configura o webdriver\n",
        "navegador = webdriver.Chrome(options=chrome_options)\n",
        "\n",
        "\n",
        "# URL da página alvo\n",
        "url = \"https://www.sspds.ce.gov.br/estatisticas-2-3/\"\n",
        "\n",
        "# Lista para armazenar os links dos PDFs\n",
        "pdf_links = []\n",
        "\n",
        "# Obtendo o conteúdo da página\n",
        "navegador.get(url)\n",
        "soup = BeautifulSoup(navegador.page_source, 'html.parser')\n",
        "\n",
        "# Encontrando todos os links na página\n",
        "links = soup.find_all('a', class_='box')\n",
        "\n",
        "# print(links)\n",
        "\n",
        "\n",
        "# Filtrando apenas os links que contêm meses e anos\n",
        "for link in links:\n",
        "    if any(mes_ano in link['href'] for mes_ano in [\"Janeiro\", \"Fevereiro\", \"Março\", \"Abril\", \"Maio\", \"Junho\", \"Julho\", \"Agosto\", \"Setembro\", \"Outubro\", \"Novembro\", \"Dezembro\"]):\n",
        "        pdf_links.append(link['href'])\n",
        "\n",
        "# print(pdf_links)\n",
        "\n",
        "# Iterando sobre os links dos PDFs\n",
        "# for pdf_link in pdf_links:\n",
        "    # Fazendo o download do PDF\n",
        "    # response = requests.get(pdf_link)\n",
        "    # pdf_data = response.content\n",
        "\n",
        "# Iterando sobre os links dos PDFs\n",
        "for pdf_link in pdf_links:\n",
        "    navegador.get(pdf_link)\n",
        "    sleep(1)  # Aguarde o carregamento da página\n",
        "    # Simule um clique no link de download\n",
        "    download_link = navegador.find_element(By.CSS_SELECTOR, 'a[href$=\".pdf\"]')\n",
        "    #download_link.click()\n",
        "    sleep(5)\n",
        "\n",
        "\n",
        "navegador.quit()\n"
      ],
      "metadata": {
        "id": "HHdGmK35f4OG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pdfplumber"
      ],
      "metadata": {
        "id": "gzKA8cRBoY4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "caminho_atual = os.getcwd()\n",
        "print(\"O diretório atual é:\", caminho_atual)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oV9JpSy6pQJv",
        "outputId": "124a16ba-fb0d-4942-81e9-b8879475b648"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O diretório atual é: /content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pdfplumber\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Lista para armazenar os dados extraídos dos PDFs\n",
        "dados_pdf = []\n",
        "\n",
        "# Diretório onde os PDFs estão salvos\n",
        "diretorio_pdf = '/content'\n",
        "\n",
        "# Iterar sobre os PDFs baixados\n",
        "for pdf_file in os.listdir(diretorio_pdf):\n",
        "    if pdf_file.endswith(\".pdf\"):\n",
        "        pdf_path = os.path.join(diretorio_pdf, pdf_file)\n",
        "        with pdfplumber.open(pdf_path) as pdf:\n",
        "            texto_pdf = \"\"\n",
        "            for page in pdf.pages:\n",
        "                texto_pdf += page.extract_text()\n",
        "        # Aqui você pode processar o texto extraído conforme necessário\n",
        "        # Por exemplo, dividir o texto em linhas e extrair os dados relevantes\n",
        "        dados_pdf.append({'Nome do PDF': pdf_file, 'Texto': texto_pdf})\n",
        "\n",
        "# Criar DataFrame a partir dos dados extraídos\n",
        "df = pd.DataFrame(dados_pdf)\n",
        "\n",
        "# Salvar o DataFrame como uma planilha do Excel\n",
        "excel_path = '/content/resultado.xlsx'\n",
        "df.to_excel(excel_path, index=False)\n",
        "\n",
        "print(\"Planilha do Excel criada com sucesso:\", excel_path)\n"
      ],
      "metadata": {
        "id": "8TR5NyGxoWVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pdfplumber\n",
        "import pandas as pd\n",
        "\n",
        "# Função para extrair e estruturar os dados do texto do PDF\n",
        "def extrair_dados_pdf(texto):\n",
        "    # Divida o texto em linhas\n",
        "    linhas = texto.split('\\n')\n",
        "\n",
        "    # Lista para armazenar os dados estruturados\n",
        "    dados = []\n",
        "\n",
        "    # Iterar sobre as linhas e extrair os dados\n",
        "    for linha in linhas:\n",
        "        # Exemplo de processamento básico - ajuste conforme necessário\n",
        "        if 'ID:' in linha:\n",
        "            # Extrair os dados da linha\n",
        "            dados_linha = linha.split(',')\n",
        "            # Adicionar os dados à lista\n",
        "            dados.append({\n",
        "                'ID': dados_linha[0].split(':')[1].strip(),\n",
        "                'AIS': dados_linha[1].split(':')[1].strip(),\n",
        "                'MUNICÍPIO': dados_linha[2].split(':')[1].strip(),\n",
        "                'NATUREZA DO FATO': dados_linha[3].split(':')[1].strip(),\n",
        "                'MEIO EMPREGADO': dados_linha[4].split(':')[1].strip(),\n",
        "                'DATA': dados_linha[5].split(':')[1].strip(),\n",
        "                'SEXO': dados_linha[6].split(':')[1].strip(),\n",
        "                'IDADE': dados_linha[7].split(':')[1].strip()\n",
        "            })\n",
        "\n",
        "    return dados\n",
        "\n",
        "# Diretório onde os PDFs estão salvos\n",
        "diretorio_pdf = \"/content\"\n",
        "\n",
        "# Lista para armazenar os dados extraídos dos PDFs\n",
        "dados_pdf = []\n",
        "\n",
        "# Iterar sobre os PDFs baixados\n",
        "for pdf_file in os.listdir(diretorio_pdf):\n",
        "    if pdf_file.endswith(\".pdf\"):\n",
        "        pdf_path = os.path.join(diretorio_pdf, pdf_file)\n",
        "        with pdfplumber.open(pdf_path) as pdf:\n",
        "            texto_pdf = \"\"\n",
        "            for page in pdf.pages:\n",
        "                texto_pdf += page.extract_text()\n",
        "        dados_pdf.extend(extrair_dados_pdf(texto_pdf))\n",
        "\n",
        "# Criar DataFrame a partir dos dados extraídos\n",
        "df = pd.DataFrame(dados_pdf)\n",
        "\n",
        "# Caminho para salvar a planilha do Excel\n",
        "excel_path = '/content/resultado.xlsx'\n",
        "\n",
        "# Salvar o DataFrame como uma planilha do Excel\n",
        "df.to_excel(excel_path, index=False)\n",
        "\n",
        "print(\"Planilha do Excel criada com sucesso:\", excel_path)\n"
      ],
      "metadata": {
        "id": "_nfJD5UssAg4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFG3VrX7tOTd",
        "outputId": "e2406ee1-0800-42fe-a171-57fe4d6b1143"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m153.6/232.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import PyPDF2\n",
        "import pandas as pd\n",
        "\n",
        "# Abrir o arquivo PDF\n",
        "pdf_file = open('CVLI-Diario-para-o-Site-Janeiro-de-2024.pdf', 'rb')\n",
        "pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
        "\n",
        "# Extrair o texto de todas as páginas\n",
        "text = ''\n",
        "for page_num in range(len(pdf_reader.pages)):\n",
        "    page = pdf_reader.pages[page_num]\n",
        "    text += page.extract_text()\n",
        "\n",
        "# Dividir o texto em linhas\n",
        "lines = text.split('\\n')\n",
        "\n",
        "# Criar uma lista de listas com os dados\n",
        "data = []\n",
        "headers = ['ID', 'AIS', 'MUNICÍPIO', 'NATUREZA DO FATO', 'MEIO EMPREGADO', 'DATA', 'SEXO', 'IDADE']\n",
        "\n",
        "for line in lines:\n",
        "    if line.startswith('ID AIS'):\n",
        "        continue  # Ignorar a linha de cabeçalho original\n",
        "    elif not line.startswith('DADOS CONSOLIDADOS') and not line.startswith('VÍTIMAS DE CRIMES VIOLENTOS LETAIS INTENCIONAIS'):\n",
        "        line_data = line.split()\n",
        "        if len(line_data) == len(headers):\n",
        "            data.append(line_data)\n",
        "\n",
        "# Criar um DataFrame com os dados\n",
        "df = pd.DataFrame(data, columns=headers)\n",
        "\n",
        "# Salvar o DataFrame em um arquivo CSV\n",
        "df.to_excel('planilha.xlsx', index=False)"
      ],
      "metadata": {
        "id": "68U6ukTBuhrn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1nQEexaMyNSO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}